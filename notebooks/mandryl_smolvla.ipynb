{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQUk3Y0WwYZ4"
      },
      "source": [
        "# ðŸ¤— x ðŸª¾: Mandryl's Training SmolVLA with LeRobot Notebook\n",
        "\n",
        "Welcome to the **LeRobot SmolVLA training notebook**! This notebook provides a ready-to-run setup for training imitation learning policies using the [ðŸ¤— LeRobot](https://github.com/huggingface/lerobot) library. The majority of this notebook was written by the team at Huggingface, with small updates to make it *actually work* from the team at Mandryl.\n",
        "\n",
        "In this example, we train an `SmolVLA` policy using a dataset hosted on the [Hugging Face Hub](https://huggingface.co/), and optionally track training metrics with [Weights & Biases (wandb)](https://wandb.ai/).\n",
        "\n",
        "## âš™ï¸ Requirements\n",
        "- A Hugging Face dataset repo ID containing your training data (`--dataset.repo_id=YOUR_USERNAME/YOUR_DATASET`)\n",
        "- Optional: A [wandb](https://wandb.ai/) account if you want to enable training visualization\n",
        "- Recommended: GPU runtime (e.g., NVIDIA A100) for faster training\n",
        "\n",
        "## â±ï¸ Expected Training Time\n",
        "Training with the `SmolVLA` policy for 20,000 steps typically takes **about 3.5 hours on an NVIDIA A100** GPU. On less powerful GPUs, training may take significantly longer!\n",
        "\n",
        "## Example Output\n",
        "Model checkpoints, logs, and training plots will be saved to the specified `--output_dir`. If `wandb` is enabled, progress will also be visualized in your wandb project dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOJyX0CnwA5m"
      },
      "source": [
        "## Install conda\n",
        "This cell uses `condacolab` to bootstrap a full Conda environment inside Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QlKjL1X5t_zM"
      },
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxCc3CARwUjN"
      },
      "source": [
        "## Install LeRobot\n",
        "This cell clones the `lerobot` repository from Hugging Face, installs FFmpeg (version 7.1.1), and installs the package in editable mode.\n",
        "Lerobot version 0.4.4 is specifically used here as it has been validated to work for this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dgLu7QT5tUik"
      },
      "source": [
        "!conda install ffmpeg=7.1.1 -c conda-forge\n",
        "!pip install \"https://github.com/huggingface/lerobot/archive/33cad37054c2b594ceba57463e8f11ee374fa93c.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Sn2wG4wldo"
      },
      "source": [
        "## Weights & Biases and HF Hub login\n",
        "This cell logs you into Weights & Biases (wandb) to enable experiment tracking and logging, and HF Hub log-in to make sure the model is saved correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PolVM_movEvp"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeK5s956BjOz"
      },
      "source": [
        "## Huggingface Hub Login\n",
        "This cell logs you into you account on the Huggingface Hub. This step is **very important**. If you skip this step, your train won't upload to the hub and will error out just before it finishes. Although there shouldn't be a problem as checkpoints are enabled (see below), it is better to be safe than sorry.\n",
        "\n",
        "How do you create a Huggingface Hub account and get your API key? Follow this link to create an account [here](https://huggingface.co/). Once an account is created, navigate to your user profile -> Settings -> Access Tokens. Copy your access token and place below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8yu5khQGIHi6"
      },
      "source": [
        "!huggingface-cli login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Hub constants\n",
        "\n",
        "Set the following constants to match your Hugging Face username, dataset repo, model repo name, and job name. They are used in the training command below so you can change them in one place. **Recommended dataset**: `lerobot/svla_so100_pickplace` (set as default for `dataset_repo_id` below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "HF_USER = \"YOUR_HF_USERNAME\"       # Your Hugging Face Hub username (for uploading the trained model)\n",
        "dataset_repo_id = \"lerobot/svla_so100_pickplace\"  # Recommended dataset. For your own: f\"{HF_USER}/{mydataset}\"\n",
        "mydataset = \"YOUR_DATASET\"         # Your dataset repo name when using your own (use with HF_USER in dataset_repo_id)\n",
        "my_smolvla = \"my_smolvla\"         # Repo name for the trained model on the Hub\n",
        "my_smolvla_training = \"my_smolvla_training\"  # Job name for logging and wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlI6fN8cTasU"
      },
      "source": [
        "## Install SmolVLA dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_3Uu-RQ8TasU"
      },
      "source": [
        "!cd lerobot && pip install -e \".[smolvla]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkzTo4mNwxaC"
      },
      "source": [
        "## Start training SmolVLA with LeRobot\n",
        "\n",
        "This cell runs the `train.py` script from the `lerobot` library to train a robot control policy.\n",
        "\n",
        "Make sure to adjust the following arguments to your setup:\n",
        "\n",
        "1.`--policy.path=lerobot/smolvla_base` uses the `smolvla_base` as the base policy / model here. Theoretically any available model can be used, but performance and training time will be far less optimal.\n",
        "\n",
        "2. `--dataset.repo_id`: Set `dataset_repo_id` in the constants section above. **Recommended**: `lerobot/svla_so100_pickplace`. For your own dataset use `f\"{HF_USER}/{mydataset}\"` (e.g. `pepijn223/il_gym0`).\n",
        "\n",
        "3. `--batch_size=64`: means the model processes 64 training samples in parallel before doing one gradient update. Reduce this number if you have a GPU with low memory.\n",
        "\n",
        "4. `--output_dir=outputs/train/...`:  \n",
        "   Directory where training logs and model checkpoints will be saved.\n",
        "\n",
        "5. `--job_name=...`:  \n",
        "   A name for this training job, used for logging and Weights & Biases.\n",
        "\n",
        "6. `--policy.device=cuda`:  \n",
        "   Use `cuda` if training on an NVIDIA GPU. Use `mps` for Apple Silicon, or `cpu` if no GPU is available.\n",
        "\n",
        "7. `--wandb.enable=true`:  \n",
        "   Enables Weights & Biases for visualizing training progress. You must be logged in via `wandb login` before running this.\n",
        "\n",
        "8. `--rename_map`\n",
        "   When your dataset uses different observation key names than what the policy expects, you must use `--rename_map` to map them at training time.\n",
        "\n",
        "Once training finishes, the final model will be available at your output directory, plus on the Hub. Make sure to download your outputs folder from the Colab workspace as it will disapear when you refresh the session. The model will still be available on the Hub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jkFF8sebTasV"
      },
      "source": [
        "!cd /content/lerobot && lerobot-train \\\n",
        "  --policy.path=lerobot/smolvla_base \\\n",
        "  --policy.repo_id=$HF_USER/$my_smolvla \\\n",
        "  --dataset.repo_id=$dataset_repo_id \\\n",
        "  --batch_size=64 \\\n",
        "  --steps=20000 \\\n",
        "  --save_checkpoint=true \\\n",
        "  --save_freq=2000 \\\n",
        "  --output_dir=outputs/train/$my_smolvla \\\n",
        "  --job_name=$my_smolvla_training \\\n",
        "  --policy.device=cuda \\\n",
        "  --wandb.enable=true \\\n",
        "  --rename_map='{\"observation.images.up\": \"observation.images.camera1\", \"observation.images.side\": \"observation.images.camera2\"}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eka07UHqMvjJ"
      },
      "source": [
        "Once the train finishes, that's it! View your dataset in the Hub and follow the provided instructions to run inference."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}